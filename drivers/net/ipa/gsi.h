// SPDX-License-Identifier: GPL-2.0

/* Copyright (c) 2015-2018, The Linux Foundation. All rights reserved.
 * Copyright (C) 2018 Linaro Ltd.
 */
#ifndef _GSI_H_
#define _GSI_H_

#include <linux/device.h>
#include <linux/types.h>
#include <linux/completion.h>
#include <linux/mutex.h>
#include <linux/spinlock.h>
#include <linux/platform_device.h>

#include "ipahal.h"

#define GSI_EVT_RING_ELEMENT_SIZE	16	/* bytes */
#define GSI_CHAN_RING_ELEMENT_SIZE	16	/* bytes */

/** struct ipa_gsi_ep_config - IPA GSI endpoint configurations
 *
 * @ipa_ep_num: IPA EP pipe number
 * @ipa_gsi_chan_num: GSI channel number
 * @ipa_if_tlv: number of IPA_IF TLV
 * @ipa_if_aos: number of IPA_IF AOS
 * @ee: Execution environment
 */
struct ipa_gsi_ep_config {
	u32 ipa_ep_num;
	u32 ipa_gsi_chan_num;
	u32 ipa_if_tlv;
	u32 ipa_if_aos;
	u32 ee;
};

/** gsi_chan_props - Channel related properties
 *
 * @dir:	     channel direction
 * @ch_id:	     virtual channel ID
 * @evt_ring_hdl:    handle of associated event ring. set to ~0 if no
 *		     event ring associated
 * @re_size:	     size of channel ring element
 * @ring_len:	     length of ring in bytes (must be integral multiple of
 *		     re_size)
 * @ring_base_addr:  physical base address of ring. Address must be aligned to
 *		     ring_len rounded to power of two
 * @ring_base_vaddr: virtual base address of ring (set to NULL when not
 *		     applicable)
 * @use_db_engine:   false => direct mode (doorbells are written directly to
 *		     RE engine)
 *		     true => DB mode (doorbells are written to DB engine)
 * @max_prefetch:    limit number of pre-fetch segments for channel
 * @low_weight:	     low channel weight (priority of channel for RE engine
 *		     round robin algorithm); must be >= 1
 * @xfer_cb:	     transfer notification callback (or NULL if not needed)
 *		     this callback happens on event boundaries
 *
 *		     e.g. 1
 *
 *		     out TD with 3 REs
 *
 *		     RE1: EOT=0, EOB=0, CHAIN=1;
 *		     RE2: EOT=0, EOB=0, CHAIN=1;
 *		     RE3: EOT=1, EOB=0, CHAIN=0;
 *
 *		     the callback will be triggered for RE3 using the
 *		     xfer_user_data of that RE
 *
 *		     e.g. 2
 *
 *		     in REs
 *
 *		     RE1: EOT=1, EOB=0, CHAIN=0;
 *		     RE2: EOT=1, EOB=0, CHAIN=0;
 *		     RE3: EOT=1, EOB=0, CHAIN=0;
 *
 *		     received packet consumes all of RE1, RE2 and part of RE3
 *		     for EOT condition. there will be three callbacks in below
 *		     order
 *
 *		     callback for RE1 using GSI_CHAN_EVT_OVERFLOW
 *		     callback for RE2 using GSI_CHAN_EVT_OVERFLOW
 *		     callback for RE3 using GSI_CHAN_EVT_EOT
 *
 * @chan_user_data:  cookie used for notifications
 *
 * All the callbacks are in interrupt context
 */
struct gsi_chan_props {
	struct ipa_mem_buffer mem;
	u32 ring_size;			/* bytes */
	bool from_gsi;
	bool use_db_engine;
	u8 low_weight;
	u8 ch_id;
	unsigned long evt_ring_hdl;
	void *chan_user_data;
};

enum gsi_xfer_flag {
	GSI_XFER_FLAG_CHAIN = 0x1,
	GSI_XFER_FLAG_EOB = 0x100,
	GSI_XFER_FLAG_EOT = 0x200,
	GSI_XFER_FLAG_BEI = 0x400
};

enum gsi_xfer_elem_type {
	GSI_XFER_ELEM_DATA,
	GSI_XFER_ELEM_IMME_CMD,
	GSI_XFER_ELEM_NOP,
};

/** gsi_xfer_elem - Metadata about a single transfer
 *
 * @addr:	    physical address of buffer
 * @len:	    size of buffer for GSI_XFER_ELEM_DATA:
 *		    for outbound transfers this is the number of bytes to
 *		    transfer.
 *		    for inbound transfers, this is the maximum number of
 *		    bytes the host expects from device in this transfer
 *
 *		    immediate command opcode for GSI_XFER_ELEM_IMME_CMD
 * @flags:	    transfer flags, OR of all the applicable flags
 *
 *		    GSI_XFER_FLAG_BEI: Block event interrupt
 *		    1: Event generated by this ring element must not assert
 *		    an interrupt to the host
 *		    0: Event generated by this ring element must assert an
 *		    interrupt to the host
 *
 *		    GSI_XFER_FLAG_EOT: Interrupt on end of transfer
 *		    1: If an EOT condition is encountered when processing
 *		    this ring element, an event is generated by the device
 *		    with its completion code set to EOT.
 *		    0: If an EOT condition is encountered for this ring
 *		    element, a completion event is not be generated by the
 *		    device, unless IEOB is 1
 *
 *		    GSI_XFER_FLAG_EOB: Interrupt on end of block
 *		    1: Device notifies host after processing this ring element
 *		    by sending a completion event
 *		    0: Completion event is not required after processing this
 *		    ring element
 *
 *		    GSI_XFER_FLAG_CHAIN: Chain bit that identifies the ring
 *		    elements in a TD
 *
 * @type:	    transfer type
 *
 *		    GSI_XFER_ELEM_DATA: for all data transfers
 *		    GSI_XFER_ELEM_IMME_CMD: for IPA immediate commands
 *		    GSI_XFER_ELEM_NOP: for event generation only
 *
 * @xfer_user_data: cookie used in xfer_cb
 */
struct gsi_xfer_elem {
	u64 addr;
	u16 len;
	u16 flags;
	enum gsi_xfer_elem_type type;
	void *xfer_user_data;
};

struct gsi_ctx;
struct gsi_ctx *gsi_init(struct platform_device *pdev, u32 ee);

/** gsi_register_device - Peripheral should call this function to
 * register itself with GSI before invoking any other APIs
 *
 * @Return 0 if successful or a negative error code otherwise.
 */
int gsi_register_device(void);

/** gsi_deregister_device - Peripheral should call this function to
 * de-register itself with GSI
 *
 * @Return 0, or a negative errno
 */
int gsi_deregister_device(void);

/** gsi_firmware_size_ok - Verify that a firmware image having the
 * given base address and size is suitable
 *
 * @Return true if values are OK, false otherwise
 */
bool gsi_firmware_size_ok(u32 base, u32 size);

/** gsi_firmware_enable - Enable firmware after loading */
void gsi_firmware_enable(void);

/** gsi_alloc_evt_ring - Peripheral should call this function to
 * allocate an event ring once gsi_register_device() has been called
 *
 * This function can sleep
 *
 * @Return Client handle populated by GSI, or a negative errno
 */
long gsi_alloc_evt_ring(u32 size, u16 int_modt);

/** gsi_dealloc_evt_ring - Peripheral should call this function to
 * de-allocate an event ring. There should not exist any active
 * channels using this event ring
 *
 * @evt_ring_hdl:  Client handle previously obtained from gsi_alloc_evt_ring
 *
 * This function can sleep
 */
void gsi_dealloc_evt_ring(unsigned long evt_ring_hdl);

/** gsi_reset_evt_ring - Peripheral should call this function to
 * reset an event ring to recover from error state
 *
 * @evt_ring_hdl:  Client handle previously obtained from
 *	       gsi_alloc_evt_ring
 *
 * This function can sleep
 */
void gsi_reset_evt_ring(unsigned long evt_ring_hdl);

/** gsi_alloc_channel - Peripheral should call this function to
 * allocate a channel once gsi_register_device() has been called
 *
 * @props:     Channel properties
 *
 * This function can sleep
 *
 * @Return Channel handle populated by GSI, opaque to client, or negative errno
 */
long gsi_alloc_channel(struct gsi_chan_props *props);

/** gsi_write_channel_scratch - Peripheral should call this function to
 * write to the scratch area of the channel context
 *
 * @chan_hdl:  Client handle previously obtained from gsi_alloc_channel
 * @tlv_size:  Number of elements in channel TLV queue
 *
 * @Return gsi_status
 */
int gsi_write_channel_scratch(unsigned long chan_hdl, u32 tlv_size);

/** gsi_start_channel - Peripheral should call this function to
 * start a channel i.e put into running state
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 *
 * This function can sleep
 *
 * @Return gsi_status
 */
int gsi_start_channel(unsigned long chan_hdl);

/** gsi_stop_channel - Peripheral should call this function to
 * stop a channel. Stop will happen on a packet boundary
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 *
 * This function can sleep
 *
 * @Return -GSI_STATUS_AGAIN if client should call stop/stop_db again
 *	   other error codes for failure
 */
int gsi_stop_channel(unsigned long chan_hdl);

/** gsi_reset_channel - Peripheral should call this function to
 * reset a channel to recover from error state
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 *
 * This function can sleep
 *
 * @Return gsi_status
 */
int gsi_reset_channel(unsigned long chan_hdl);

/** gsi_dealloc_channel - Peripheral should call this function to
 * de-allocate a channel
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 *
 * This function can sleep
 */
void gsi_dealloc_channel(unsigned long chan_hdl);

/** gsi_is_channel_empty - Peripheral can call this function to query if
 * the channel is empty. This is only applicable to GPI. "Empty" means
 * GSI has consumed all descriptors for a TO_GSI channel and SW has
 * processed all completed descriptors for a FROM_GSI channel.
 *
 * @chan_hdl:  Client handle previously obtained from gsi_alloc_channel
 *
 * @Return true if channel is empty, false otherwise
 */
bool gsi_is_channel_empty(unsigned long chan_hdl);

/** gsi_get_channel_cfg - This function returns the current config
 * of the specified channel
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 * @props:     where to copy properties to
 * @scr:       where to copy scratch info to
 *
 * @Return gsi_status
 */
int gsi_get_channel_cfg(unsigned long chan_hdl, struct gsi_chan_props *props);

/** gsi_set_channel_cfg - This function applies the supplied config
 * to the specified channel
 *
 * ch_id and evt_ring_hdl of the channel cannot be changed after
 * gsi_alloc_channel
 *
 * @chan_hdl:  Client handle previously obtained from gsi_alloc_channel
 * @props:     the properties to apply
 *
 * @Return gsi_status
 */
int gsi_set_channel_cfg(unsigned long chan_hdl, struct gsi_chan_props *props);

/** gsi_poll_channel - Peripheral should call this function to query for
 * completed transfer descriptors.
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 *
 * @Return number of bytes transferred, or a negative error code
 */
int gsi_poll_channel(unsigned long chan_hdl);

/** gsi_channel_intr_enable/disable - control channel interrupts
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 */
void gsi_channel_intr_enable(unsigned long chan_hdl);
void gsi_channel_intr_disable(unsigned long chan_hdl);

/** gsi_queue_xfer - Peripheral should call this function
 * to queue transfers on the given channel
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 * @num_xfers: Number of transfer in the array @ xfer
 * @xfer:      Array of num_xfers transfer descriptors
 * @ring_db:   If true, tell HW about these queued xfers
 *	       If false, do not notify HW at this time
 *
 * @Return gsi_status
 */
int gsi_queue_xfer(unsigned long chan_hdl, u16 num_xfers,
		   struct gsi_xfer_elem *xfer, bool ring_db);

/** gsi_start_xfer - Peripheral should call this function to
 * inform HW about queued xfers
 *
 * @chan_hdl:  Client handle previously obtained from
 *	       gsi_alloc_channel
 *
 * @Return gsi_status
 */
int gsi_start_xfer(unsigned long chan_hdl);

#endif /* _GSI_H_ */
